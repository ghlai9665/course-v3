{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "colab_gary_study_notes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "decimal-chinese"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghlai9665/course-v3/blob/master/colab_gary_study_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "restricted-mountain"
      },
      "source": [
        "Beginning after the matrix multiplication lesson, which has decent notes, but should take notes in a completely new Jupyter Notebook for better organization and retention.\n"
      ],
      "id": "restricted-mountain"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "worse-greeting"
      },
      "source": [
        "# Forward Pass"
      ],
      "id": "worse-greeting"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suited-desert"
      },
      "source": [
        "## Imports"
      ],
      "id": "suited-desert"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwbZBLc6Ql8",
        "outputId": "6ed913ad-bb4a-4ad9-cb2f-b7741cb82f77"
      },
      "source": [
        "# workaround to download mnist data, set root to './', run and proceed, \n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "root = './'\n",
        "torchvision.datasets.MNIST(root=root,download=True)"
      ],
      "id": "DLwbZBLc6Ql8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-14 13:49:36--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-14 13:49:37--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [        <=>         ]  33.20M  5.96MB/s    in 16s     \n",
            "\n",
            "2021-03-14 13:49:53 (2.09 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sixth-broadcast",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916764e0-41da-4772-aa85-4f8ce1fff84e"
      },
      "source": [
        "!pip show torchvision"
      ],
      "id": "sixth-broadcast",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: torchvision\n",
            "Version: 0.9.0+cu101\n",
            "Summary: image and video datasets and models for torch deep learning\n",
            "Home-page: https://github.com/pytorch/vision\n",
            "Author: PyTorch Core Team\n",
            "Author-email: soumith@pytorch.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: torch, pillow, numpy\n",
            "Required-by: fastai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTMXQ635j60H"
      },
      "source": [
        "import operator\n",
        "\n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "def test_near(a,b): test(a,b,near)\n",
        "\n",
        "# Make MNIST data work on Google Colab\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ],
      "id": "CTMXQ635j60H",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os2A_3jd7d66"
      },
      "source": [
        "from torch import nn"
      ],
      "id": "Os2A_3jd7d66",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "specific-durham"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "def get_data():\n",
        "    import os\n",
        "    import torchvision.datasets as datasets\n",
        "    # root = '../data'\n",
        "\n",
        "    if not os.path.exists(root):\n",
        "        os.mkdir(root)\n",
        "    train_set = datasets.MNIST(root=root, train=True, download=True)\n",
        "    test_set = datasets.MNIST(root=root, train=False, download=True)\n",
        "    x_train, x_valid = train_set.train_data.split([50000, 10000])\n",
        "    y_train, y_valid = train_set.train_labels.split([50000, 10000])\n",
        "    return (x_train.view(50000, -1) / 256.0), y_train.float(), (x_valid.view(10000, -1))/ 256.0, y_valid.float()\n",
        "\n",
        "# The geographic intuition for this is picturing x's around a horizontal line (mean), bring that mean down to 0,\n",
        "# then scale x's by dividing them by the standard deviation\n",
        "def normalize(x, mean, std): return (x-mean)/std"
      ],
      "id": "specific-durham",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raised-lebanon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "321be2df-de83-45ed-d907-a9cd3d063b70"
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "id": "raised-lebanon",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alien-healing"
      },
      "source": [
        "## Normalization"
      ],
      "id": "alien-healing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rental-cliff"
      },
      "source": [
        "- We want mean to be 0 and standard deviation to be 1 for easier convergence, so we normalize. \n",
        "- Notice how we use train_mean and train_std to normalize valid data as well - that's because we don't want validation dataset to be in a different scale"
      ],
      "id": "rental-cliff"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "graduate-stewart",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af78d2d7-aaa3-429a-f4ab-ab66a48ff6b8"
      },
      "source": [
        "# before normalization\n",
        "train_mean, train_std = x_train.mean(), x_train.std()\n",
        "train_mean, train_std"
      ],
      "id": "graduate-stewart",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weighted-living"
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "id": "weighted-living",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "controlled-speech",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99961ef-ed8b-4b03-fe48-59ee014a3202"
      },
      "source": [
        "# after normalization\n",
        "train_mean, train_std = x_train.mean(), x_train.std()\n",
        "train_mean, train_std"
      ],
      "id": "controlled-speech",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.9162e-08), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voluntary-brief"
      },
      "source": [
        "def assert_is_near_zero(a, threshold=1e-3): assert a.abs() < threshold, f\"{a} is not near zero\"\n",
        "assert_is_near_zero(train_mean)"
      ],
      "id": "voluntary-brief",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "collect-democrat"
      },
      "source": [
        "## Get shapes"
      ],
      "id": "collect-democrat"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "partial-nature",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3958f591-d000-438e-8493-f1c6973a4ff6"
      },
      "source": [
        "num_samples, image_size = x_train.shape \n",
        "num_classes = y_train.max() + 1 \n",
        "nh = 50\n",
        "\n",
        "n = num_samples\n",
        "m = image_size\n",
        "c = num_classes\n",
        "\n",
        "n, m, c, nh"
      ],
      "id": "partial-nature",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10.), 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "equal-service"
      },
      "source": [
        "## Intialization"
      ],
      "id": "equal-service"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pediatric-authority"
      },
      "source": [
        "- Initialization is *extremely* important. In 2019, they wrote a paper \"Fixup Initialization: Residual Learning Without Normalization\" in which they trained a 10,000 layer neural net WITHOUT normalization just by initializing everything carefully."
      ],
      "id": "pediatric-authority"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "democratic-columbia"
      },
      "source": [
        "### Xavier Initialization\n",
        "\n",
        "- To perform Standard Xavier Initialization, you just divide input by the sqrt(num_input_units), which would give you a mean of 0, and standard deviation of 1 / sqrt(m)"
      ],
      "id": "democratic-columbia"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lucky-monroe"
      },
      "source": [
        "def lin(x, w, b): return x@w + b"
      ],
      "id": "lucky-monroe",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mediterranean-nation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79f5042-f860-4042-dd1d-4de5e1d4f7ad"
      },
      "source": [
        "# Forward pass without Initialization\n",
        "w1 = torch.randn(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "\n",
        "t = lin(x_valid, w1, b1)\n",
        "t.mean(), t.std() # terrible, you want ~ (0,1) (mean,std)"
      ],
      "id": "mediterranean-nation",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2650), tensor(28.1635))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weekly-hurricane",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba39ea0-ba37-44c0-8946-d11d2b345642"
      },
      "source": [
        "# Forward pass with Standard Xavier Init\n",
        "w1 = torch.randn(m, nh) * math.sqrt(1/m)\n",
        "b1 = torch.zeros(nh)\n",
        "\n",
        "t = lin(x_valid, w1, b1)\n",
        "t.mean(), t.std() # good"
      ],
      "id": "weekly-hurricane",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1633), tensor(0.9979))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "confused-privacy"
      },
      "source": [
        "assert_is_near_zero(w1.mean())\n",
        "assert_is_near_zero(w1.std() - 1/math.sqrt(m))"
      ],
      "id": "confused-privacy",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fourth-reverse"
      },
      "source": [
        "### Vanishing Activation/Gradient Problem\n",
        "\n",
        "- Remember after performing the matrix multiplication, you have to pass it through relu, but each time you do that, you cut all activation values that are below 0 to 0 and thereby reduces the standard deviation. If your network is very deep, your standard deviation will keep getting reduced (possibly down to 0)"
      ],
      "id": "fourth-reverse"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jewish-arkansas"
      },
      "source": [
        "![Screen Shot 2021-03-02 at 9.20.03 PM.png](attachment:a3f59b8e-febb-4866-8494-d2338a2b0374.png)"
      ],
      "id": "jewish-arkansas"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "double-agency",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485a6c3f-485f-40bb-b7fd-dec883a95a79"
      },
      "source": [
        "# clamp_min(n) means replace everything below n with n, in this case, relu means replacing everything negative with 0\n",
        "# always try to use PyTorch function because they're generally implemented in C for you\n",
        "def relu(x): return x.clamp_min(0.) \n",
        "\n",
        "t = relu(lin(x_valid, w1, b1)) \n",
        "t.mean(),t.std()"
      ],
      "id": "double-agency",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4760), tensor(0.6493))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decimal-chinese"
      },
      "source": [
        "### Kaiming Initialization\n",
        "- The problem with Xavier Initialization is that it doesn't combat the vanishing gradient problem very well. \n",
        "- Kaiming initialization is almost identical to Xavier initialization but with a 2 on top; it will keep the std around \n",
        "\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "- This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets as well as Kaiming He initialization!) \n",
        "\n",
        "- So papers by competition winners are very good because they introduce MANY good ideas instead of just one tiny tweak."
      ],
      "id": "decimal-chinese"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "level-begin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efd0d5c-ba5a-425a-ad7a-650df1b37d6d"
      },
      "source": [
        "# Forward pass with Kaiming Initialization\n",
        "torch.manual_seed(42)\n",
        "w1 = torch.randn(m, nh) * math.sqrt(2/m)\n",
        "b1 = torch.zeros(nh)\n",
        "\n",
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(), t.std() "
      ],
      "id": "level-begin",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6624), tensor(0.9097))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "violent-backing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c065134-aa07-4225-9c63-64c0465334fa"
      },
      "source": [
        "# Forward pass with PyTorch's Kaiming Initialization, same thing\n",
        "from torch.nn.init import kaiming_normal_\n",
        "\n",
        "w1 = torch.empty(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(), t.std() "
      ],
      "id": "violent-backing",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.6624), tensor(0.9097))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preceding-development"
      },
      "source": [
        "- Note: Kaiming initialization is very good but notice the mean is still not zero - we have good reasons to want them to be. So we can define our own new_relu to see if it helps with normalizing the mean. It's an intuitive thing to do and papers are written from these minor tweaks. Maybe it'll help a lot in practice"
      ],
      "id": "preceding-development"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retired-postcard"
      },
      "source": [
        "def new_relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "id": "retired-postcard",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "worldwide-recovery",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267ca1a2-dc31-4cec-e9db-a9bb64816eac"
      },
      "source": [
        "# The new_relu seems to help!\n",
        "torch.manual_seed(42)\n",
        "w1 = torch.randn(m,nh) * math.sqrt(2./m)\n",
        "t1 = new_relu(lin(x_valid, w1, b1))\n",
        "t1.mean(), t1.std()"
      ],
      "id": "worldwide-recovery",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1624), tensor(0.9097))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "living-hurricane"
      },
      "source": [
        "## Train a Model"
      ],
      "id": "living-hurricane"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inside-marketing"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "w1 = torch.empty(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "def model(x):\n",
        "    l1 = lin(x, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    l3 = lin(l2, w2, b2)\n",
        "    return l3"
      ],
      "id": "inside-marketing",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "departmental-browser",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0589e2-5703-49b2-aabe-efbc254c9c31"
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "id": "departmental-browser",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 7.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stuck-omega"
      },
      "source": [
        "assert model(x_valid).shape == torch.Size((x_valid.shape[0],1))"
      ],
      "id": "stuck-omega",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "subject-passport"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "- We wrongly use the MSE for now just for simplicity's sake"
      ],
      "id": "subject-passport"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuclear-playback"
      },
      "source": [
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "id": "nuclear-playback",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aerial-berry"
      },
      "source": [
        "y_train, y_valid = y_train.float(), y_valid.float()"
      ],
      "id": "aerial-berry",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "worse-ceiling"
      },
      "source": [
        "pred = model(x_train)"
      ],
      "id": "worse-ceiling",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unavailable-illinois",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b7f37e-fa4f-4798-aec9-ca4ab2a1f1fb"
      },
      "source": [
        "y_train.shape"
      ],
      "id": "unavailable-illinois",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defensive-refund",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a735fe-ad40-40f6-b3df-a84aa1356e14"
      },
      "source": [
        "pred.shape # not the exact shape, need to squeeze in mse"
      ],
      "id": "defensive-refund",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "retained-marketing",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7fac6f-596a-498e-fee7-f4e3b81261cc"
      },
      "source": [
        "mse(pred, y_train)"
      ],
      "id": "retained-marketing",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7683e+29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alpha-vegetarian"
      },
      "source": [
        "# Backward Pass"
      ],
      "id": "alpha-vegetarian"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lonely-anime"
      },
      "source": [
        "- During backward pass, you calculate the gradient of every w1, b1, w2, b2 with respect to the loss\n",
        "- For each of the function below, we take the derivative of each layer in terms of loss, storing the result in thatlayer's .g -- in other words, x.grad stores the result of dloss/dx. Note x is the denominator, the layer.\n",
        "- DON'T RUN THIS FUNCTION LOCALLY ON CPU. IT REQUIRES GPU!"
      ],
      "id": "lonely-anime"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "honey-complexity"
      },
      "source": [
        "def mse_grad(inp, targ):\n",
        "    # gradient of loss with respect to the previous layer, so it's pred.grad == dloss/dpred\n",
        "    inp.grad = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "id": "honey-complexity",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arranged-vermont"
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "    # inp.grad == dloss/dinp == dout/dinp * dloss/dout  \n",
        "    inp.grad = (inp > 0).float() * out.grad"
      ],
      "id": "arranged-vermont",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "solar-albuquerque"
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    # dloss / dl\n",
        "    inp.grad = out.grad @ w.t() \n",
        "    # dloss / dw\n",
        "    w.grad = (inp.unsqueeze(-1) * out.grad.unsqueeze(1)).sum(0)\n",
        "    # dloss / db\n",
        "    b.grad = out.grad.sum(0)"
      ],
      "id": "solar-albuquerque",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiBFP-KFn7IC"
      },
      "source": [
        "# Full Pass: Forward + Backward \n"
      ],
      "id": "XiBFP-KFn7IC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sixth-monkey"
      },
      "source": [
        "from torch.nn import init\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Our forward + backward loop\n",
        "\n",
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)\n",
        "\n",
        "def forward_and_backward(inp, target):\n",
        "    # forward\n",
        "    l1 = lin(inp, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    pred = lin(l2, w2, b2)\n",
        "    loss = mse(pred, target)    \n",
        "    \n",
        "    # backward\n",
        "    # pred.grad = dloss/dpred\n",
        "    mse_grad(pred, target) \n",
        "    # l2.grad = dloss/dl2 = dloss/dpred * dpred/dl2\n",
        "    # w2.grad = dloss/dw2 = dloss/dpred * dpred/dw2\n",
        "    # b2.grad = dloss/db2 = dloss/dpred * dpred/db2\n",
        "    lin_grad(l2, pred, w2, b2) \n",
        "    # l1.grad = dloss/dl1 = dloss/dl2 * dl2/dl1\n",
        "    relu_grad(l1, l2)\n",
        "    # x.grad = dloss/dx = dloss/dl1 * dl1/dx\n",
        "    # w1.grad = dloss/dw1 = dloss/dl1 * dl1/dw1\n",
        "    # b1.grad = dloss/db1 = dloss/dl1 * dl1/db1\n",
        "    lin_grad(inp, l1, w1, b1)\n",
        "\n",
        "forward_and_backward(x_train, y_train)"
      ],
      "id": "sixth-monkey",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha6vQHRhlWxP"
      },
      "source": [
        "# pytorch's forward + backward loop\n",
        "w1_2 = w1.clone().requires_grad_(True)\n",
        "w2_2 = w2.clone().requires_grad_(True)\n",
        "b1_2 = b1.clone().requires_grad_(True)\n",
        "b2_2 = b2.clone().requires_grad_(True)\n",
        "x_train_2 = x_train.clone().requires_grad_(True)\n",
        "\n",
        "def forward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = lin(inp, w1_2, b1_2)\n",
        "    l2 = relu(l1)\n",
        "    pred = lin(l2, w2_2, b2_2)\n",
        "    # we don't actually need the loss in backward!\n",
        "    return mse(pred, targ) \n",
        "\n",
        "loss = forward(x_train_2, y_train)\n",
        "loss.backward()"
      ],
      "id": "ha6vQHRhlWxP",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaK8ZibumHKV"
      },
      "source": [
        "test_near(w1_2.grad, w1.grad)\n",
        "test_near(w2_2.grad, w2.grad)\n",
        "test_near(b1_2.grad, b1.grad)\n",
        "test_near(b2_2.grad, b2.grad)\n",
        "test_near(x_train_2.grad, x_train.grad)"
      ],
      "id": "IaK8ZibumHKV",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL1Bc7s-wOKl"
      },
      "source": [
        "# Refactor Forward & Backward Functions into Same Classes"
      ],
      "id": "XL1Bc7s-wOKl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kW-BUVJwRl_"
      },
      "source": [
        "class Relu():\n",
        "  def __call__(self, input):\n",
        "    self.input = input\n",
        "    self.output = input.clamp_min(0.) \n",
        "    return self.output\n",
        "\n",
        "  def backward(self):\n",
        "    self.input.grad = (self.input > 0).float() * self.output.grad"
      ],
      "id": "-kW-BUVJwRl_",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZOL0VixycG"
      },
      "source": [
        "class Lin():\n",
        "  def __init__(self, w, b): \n",
        "    self.w = w\n",
        "    self.b = b\n",
        "\n",
        "  def __call__(self, input):\n",
        "    self.input = input\n",
        "    self.output = input@self.w + self.b\n",
        "    return self.output\n",
        "  \n",
        "  def backward(self):\n",
        "    self.input.grad = self.output.grad @ self.w.t()\n",
        "    self.w.grad = (self.input.unsqueeze(-1) * self.output.grad.unsqueeze(1)).sum(0)\n",
        "    self.b.grad = self.output.grad.sum(0)"
      ],
      "id": "tQZOL0VixycG",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OV__0al0isF"
      },
      "source": [
        "class Mse():\n",
        "  def __call__(self, pred, targ):\n",
        "    self.pred = pred\n",
        "    self.targ = targ\n",
        "    return (pred.squeeze(-1) - targ).pow(2).mean()\n",
        "\n",
        "  def backward(self):\n",
        "    self.pred.grad = 2. * (self.pred.squeeze() - self.targ).unsqueeze(-1) / self.pred.shape[0]"
      ],
      "id": "6OV__0al0isF",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqxsMKb_67Ks"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, w1, w2, b1, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    self.loss = Mse()\n",
        "  \n",
        "  def __call__(self, x, target):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return self.loss(x, target)\n",
        "  \n",
        "  def backward(self):\n",
        "    self.loss.backward()\n",
        "    for layer in reversed(self.layers):\n",
        "      layer.backward()"
      ],
      "id": "wqxsMKb_67Ks",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7WjVuZu0dtr",
        "outputId": "a7c7c68e-5fc9-41d9-d921-e9e00c227a11"
      },
      "source": [
        "w1.grad, b1.grad, w2.grad, b2.grad = [None for _ in range(4)]; print(w1.grad, b1.grad, w2.grad, b2.grad)\n",
        "model = Model(w1, w2, b1, b2)"
      ],
      "id": "x7WjVuZu0dtr",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None None None None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcOV3I8TxoLm",
        "outputId": "2a175e99-87da-4667-86bb-8a796c3efcdb"
      },
      "source": [
        "# forward pass\n",
        "%time loss = model(x_train, y_train)"
      ],
      "id": "dcOV3I8TxoLm",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 115 ms, sys: 0 ns, total: 115 ms\n",
            "Wall time: 58.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYs13Swh0ISH",
        "outputId": "405cf42b-d2bc-4eff-cd01-2c14ba57ea29"
      },
      "source": [
        "# backward pass\n",
        "%time model.backward()"
      ],
      "id": "UYs13Swh0ISH",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.98 s, sys: 3.63 s, total: 6.61 s\n",
            "Wall time: 3.43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TsDON1d0cGE"
      },
      "source": [
        "test_near(w1_2.grad, w1.grad)\n",
        "test_near(w2_2.grad, w2.grad)\n",
        "test_near(b1_2.grad, b1.grad)\n",
        "test_near(b2_2.grad, b2.grad)\n",
        "test_near(x_train_2.grad, x_train.grad)"
      ],
      "id": "5TsDON1d0cGE",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxsd4eZPAVuo"
      },
      "source": [
        "# Refactor out Repetitive Code"
      ],
      "id": "xxsd4eZPAVuo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoA3zhL4wPuo"
      },
      "source": [
        "### Notice how we're basically recreating nn.Linear and nn.Module etc."
      ],
      "id": "xoA3zhL4wPuo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4zP9r2JAk_a"
      },
      "source": [
        "class Module():\n",
        "  def __call__(self, *args):\n",
        "    self.args = args\n",
        "    self.output = self.forward(*args)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self): self.bwd(self.output, *self.args)"
      ],
      "id": "a4zP9r2JAk_a",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhL7Hd88e84A"
      },
      "source": [
        "'''\n",
        "Module is the one that takes in all the arguments during dumb call __call__ and pass them down to the \n",
        "specific forward / bwd. There are no self.input, only self.args and self.output.\n",
        "'''\n",
        "\n",
        "# Relu(input), *args is input\n",
        "class Relu(Module):\n",
        "  def forward(self, input):\n",
        "    return input.clamp_min(0.) \n",
        "\n",
        "  def bwd(self, output, input):\n",
        "    input.grad = (input > 0).float() * output.grad"
      ],
      "id": "RhL7Hd88e84A",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKwL9gsMflAj"
      },
      "source": [
        "# Lin(input), *args is input\n",
        "class Lin(Module):\n",
        "  def __init__(self, w, b): \n",
        "    self.w, self.b = w, b\n",
        "\n",
        "  def forward(self, input):\n",
        "    return input@self.w + self.b\n",
        "  \n",
        "  def bwd(self, output, input):\n",
        "    input.grad = output.grad @ self.w.t()\n",
        "    # optimization via matrix multiplication instead of multiplication and summing (einsum could also be used to improve performance here)\n",
        "    self.w.grad = input.t() @ output.grad\n",
        "    self.b.grad = output.grad.sum(0)\n",
        "    # print(\"input, w, b shapes: \", input.shape, self.w.shape, self.b.shape)\n",
        "    # print(\"input.grad, w.grad, b.grad shapes: \", input.grad.shape, self.w.grad.shape, self.b.grad.shape)"
      ],
      "id": "JKwL9gsMflAj",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoYB9ZfMkKC3"
      },
      "source": [
        "# Mse(input), *args are pred and targ\n",
        "class Mse(Module):\n",
        "  def forward(self, pred, targ):\n",
        "    return (pred.squeeze(-1) - targ).pow(2).mean()\n",
        "\n",
        "  def bwd(self, out, pred, targ):\n",
        "    pred.grad = 2. * (pred.squeeze() - targ).unsqueeze(-1) / pred.shape[0]\n"
      ],
      "id": "eoYB9ZfMkKC3",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CEvRGRBleFN"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, w1, w2, b1, b2):\n",
        "    self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
        "    self.loss = Mse()\n",
        "  \n",
        "  def __call__(self, x, target):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return self.loss(x, target)\n",
        "  \n",
        "  def backward(self):\n",
        "    self.loss.backward()\n",
        "    for layer in reversed(self.layers):\n",
        "      layer.backward()"
      ],
      "id": "4CEvRGRBleFN",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLMj-YPFlp9t",
        "outputId": "9ded655e-f726-4728-d185-f88164d537d9"
      },
      "source": [
        "w1.grad, b1.grad, w2.grad, b2.grad = [None for _ in range(4)]; print(w1.grad, b1.grad, w2.grad, b2.grad)\n",
        "model = Model(w1, w2, b1, b2)"
      ],
      "id": "vLMj-YPFlp9t",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None None None None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNm6-bkoltWH",
        "outputId": "ebf0da43-a076-4e04-ecfc-a68407f7a01e"
      },
      "source": [
        "# forward pass\n",
        "%time loss = model(x_train, y_train)"
      ],
      "id": "sNm6-bkoltWH",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 99.5 ms, sys: 0 ns, total: 99.5 ms\n",
            "Wall time: 49.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRuEofSglt2T",
        "outputId": "963b94c3-2951-466d-9165-6207b5605836"
      },
      "source": [
        "# backward pass\n",
        "%time model.backward()"
      ],
      "id": "TRuEofSglt2T",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 243 ms, sys: 29.8 ms, total: 273 ms\n",
            "Wall time: 151 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQQjSCxfozHy"
      },
      "source": [
        "test_near(w1_2.grad, w1.grad)\n",
        "test_near(w2_2.grad, w2.grad)\n",
        "test_near(b1_2.grad, b1.grad)\n",
        "test_near(b2_2.grad, b2.grad)\n",
        "test_near(x_train_2.grad, x_train.grad)"
      ],
      "id": "IQQjSCxfozHy",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3cm3rE01qvC"
      },
      "source": [
        "# Lesson 9 \n",
        "\n",
        "# How to do Research"
      ],
      "id": "b3cm3rE01qvC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueUFGrAD1wKK"
      },
      "source": [
        "- If you see something weird in PyTorch code, don't assume it's correct. \n",
        "- When it comes to deep learning, no one knows what he's doing. And also a lot of the code is just that way because of legacy and no longer a good idea. It's important to question the status quo.\n",
        "- Re-implement from scratch, play with it, do experiments with it to see if it actually gives better results. (example of what Jeremy did in 02a and 02b notebooks) If not, reach out to the team and ask why. You can publish your results by converting your Jupyter Notebook into Gist with Gist It. \n"
      ],
      "id": "ueUFGrAD1wKK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea1Mu2-D1hp1"
      },
      "source": [
        "## Cross Entropy Loss"
      ],
      "id": "ea1Mu2-D1hp1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6ByMba1ks1"
      },
      "source": [
        "# use nn.Linear and don't write how to deal with loss into the model yet\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, output_dim)]\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ],
      "id": "Ag6ByMba1ks1",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IcjJjmn8Wik",
        "outputId": "4f06a77d-08fc-4ecc-f373-1f7ad0364daf"
      },
      "source": [
        "int(c)"
      ],
      "id": "6IcjJjmn8Wik",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HboMldcb5WIE"
      },
      "source": [
        "model = Model(m, nh, int(c))"
      ],
      "id": "HboMldcb5WIE",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMHaGsnO7tax"
      },
      "source": [
        "To get the cross entropy loss, we first pass the numerical values through a softmax. Then do $$ -\\sum x\\, \\log p(x) $$\n"
      ],
      "id": "QMHaGsnO7tax"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXyNoOMH7rG1"
      },
      "source": [
        "def log_softmax(x): return (x.exp() / x.exp().sum(-1, keepdim=True)).log()"
      ],
      "id": "IXyNoOMH7rG1",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzVnQiLF7obK"
      },
      "source": [
        "pred = model(x_train) # numerical value\n",
        "pred = log_softmax(pred) # a softmax"
      ],
      "id": "pzVnQiLF7obK",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioUEe3BX9Uv3"
      },
      "source": [
        "Let's look at the targets for the first 3 images"
      ],
      "id": "ioUEe3BX9Uv3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IzJSE-Q8n07",
        "outputId": "0c2b76d2-8450-4fcf-ecc6-4f5821bc8d88"
      },
      "source": [
        "y_train[:3]"
      ],
      "id": "9IzJSE-Q8n07",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 0., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-RanI029dDf"
      },
      "source": [
        "And our model's prediction for them (keep in mind only the target class matter since we're dealing with one-hot vectors here)"
      ],
      "id": "F-RanI029dDf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcYLNT0u9AKW",
        "outputId": "bec87dbf-e5d5-4dd9-ea75-5c1831c96b76"
      },
      "source": [
        "print(pred[0][5])\n",
        "print(pred[1][0])\n",
        "print(pred[2][4])"
      ],
      "id": "KcYLNT0u9AKW",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-2.5021, grad_fn=<SelectBackward>)\n",
            "tensor(-2.1583, grad_fn=<SelectBackward>)\n",
            "tensor(-2.4839, grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17yZ11Pk9QPX",
        "outputId": "599e3bef-a3a6-4cab-e2a6-0a833b852d1d"
      },
      "source": [
        "# numpy / pytorch trick to get them quicker, these are the class in the softmax (p(x)) that matter\n",
        "pred[[0,1,2],[5,0,4]]"
      ],
      "id": "17yZ11Pk9QPX",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.5021, -2.1583, -2.4839], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unqgKyBTGZcS",
        "outputId": "c68e0c6a-3713-49dc-af21-c3606f74a097"
      },
      "source": [
        "y_train.long()"
      ],
      "id": "unqgKyBTGZcS",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 8, 4, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_xfXNAB9wqR"
      },
      "source": [
        "# negative log likelihood loss\n",
        "# pred[range(target.shape[0]), target] selects the predicted likelihoods for the correct classes, which if you multiply by 1, gives you the loss for that image.\n",
        "# You then average all images. \n",
        "# target is a vector\n",
        "def nll(pred, target):\n",
        "  return - pred[range(target.shape[0]), target.long()].mean()"
      ],
      "id": "3_xfXNAB9wqR",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLMu36O9D_mo"
      },
      "source": [
        "### Optimization for Numerical Stability\n",
        "\n",
        "Because computers cannot do perfect math i.e. divisions can only be accurate to a certain number of decimals, computers can't tell differences between two really big but different numbers, there are mathematical tricks we can do to make the computation more stable.\n",
        "\n",
        "Here we optimize log_softmax in two ways\n",
        "\n",
        "**1. Using the formula** $$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
        "\n",
        "\n",
        "**2. Use the LogSumExp trick** \n",
        "\n",
        "Reference to this great [article](https://nhigham.com/2021/01/05/what-is-the-log-sum-exp-function/).\n",
        "\n",
        "Basically \n",
        "\n",
        "$$LSE \\left (x \\right ) = \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right )$$ is called the Log Sum Exponential - it is useful because it approximates the max function max(x), but it is smooth / differentiable at all points unlike the max function. Note its property (it is very close to the max(x), bounded by a difference of log(n)): \n",
        "\n",
        "$$ \\max \\left (x \\right ) <= LSE \\left (x \\right ) <= \\max \\left (x \\right ) + \\log \\left (n \\right )$$ \n",
        "\n",
        "which is derived by taking log of $$ e^{\\max \\left (x \\right )} <= \\sum_{j=1}^{n} e^{x_{j}} <= n e^{\\max \\left (x \\right )}$$\n",
        "\n",
        "In fact, if x = [0 t], LSE approximates the ReLu, which is max(t, 0). LSE([0 t]), which is just log(1 + e^t), is known as the softplus function. It is a smooth approximation of ReLU.\n",
        "\n",
        "Now, you shouldn't type $$\\sum_{j=1}^{n} e^{x_{j}}$$ directly in PyTorch because **if x is big, you can get numerical overflow very fast (with just double-digit x) - note this is an exponential. Watch out for overflows any time you see exponentials!**\n",
        "\n",
        "So we use this trick:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "\n",
        "where a is the maximum of the $x_{j}$.\n",
        "\n",
        "Note now you will only get negative exponents. No overflow. Any underflows are harmless. \n"
      ],
      "id": "LLMu36O9D_mo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b24vh3DfFn2a"
      },
      "source": [
        "def test_log_softmax_equal(func1, func2):\n",
        "  loss1 = nll(func1(model(x_train)), y_train)\n",
        "  loss2 = nll(func2(model(x_train)), y_train)\n",
        "  test_near(loss1, loss2)"
      ],
      "id": "b24vh3DfFn2a",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-vUSlzkDjnd"
      },
      "source": [
        "# first optimization, avoid a lot of divisions (and thus inaccuracies)\n",
        "def log_softmax_1(x): \n",
        "  # the first term is really x.exp().log() but that's just x\n",
        "  return x - (x.exp().sum(-1, keepdim=True)).log()"
      ],
      "id": "t-vUSlzkDjnd",
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ8gbFLtAyzE"
      },
      "source": [
        "def logsumexp(x):\n",
        "  a = x.max(-1).values\n",
        "  return a + (x-a.unsqueeze(-1)).exp().sum(-1).log()\n",
        "# test our logsumexp against pytorch's\n",
        "pred = model(x_train)\n",
        "test_near(logsumexp(pred), pred.logsumexp(-1))\n",
        "\n",
        "# second optimization. As mentioned above, to avoid overflow, we do second optimization with LSE (log sum exponential) \n",
        "def log_softmax_2(x):\n",
        "  lse = x.logsumexp(-1) # use PyTorch's native logsumexp\n",
        "  return x - lse.unsqueeze(-1)"
      ],
      "id": "WZ8gbFLtAyzE",
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDPOFBECN_sm"
      },
      "source": [
        "# test the 2 optimized log_softmax\n",
        "test_log_softmax_equal(log_softmax, log_softmax_1)\n",
        "test_log_softmax_equal(log_softmax, log_softmax_2)\n",
        "\n",
        "# test our nll against pytorch's implementation\n",
        "pred = model(x_train)\n",
        "our_logsoftmax_nll_loss = nll(log_softmax(pred), y_train)\n",
        "torch_logsoftmax_nll_loss = F.nll_loss(F.log_softmax(pred, -1), y_train.long())\n",
        "torch_crossentropy_loss = F.cross_entropy(pred, y_train.long())\n",
        "\n",
        "test_near(our_logsoftmax_nll_loss, torch_logsoftmax_nll_loss)\n",
        "test_near(torch_logsoftmax_nll_loss, torch_crossentropy_loss)"
      ],
      "id": "IDPOFBECN_sm",
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2DPej92ve_P"
      },
      "source": [
        "Checkpoint Lesson 9 42:25"
      ],
      "id": "X2DPej92ve_P"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU0CoPBgZvRw"
      },
      "source": [
        ""
      ],
      "id": "UU0CoPBgZvRw",
      "execution_count": null,
      "outputs": []
    }
  ]
}